# -*- coding: utf-8 -*-
"""LoadForecast(PyCaret).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11oT1oEJfyO7Noty-8DKpb8SSfdzUXYAL
"""

pip install pycaret -q

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# PyCaret imports
try:
    from pycaret.time_series import *
    PYCARET_AVAILABLE = True
    print("PyCaret is available!")
except ImportError:
    print("PyCaret not available. Install with: pip install pycaret")
    PYCARET_AVAILABLE = False

# Set plotting style
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")

class PyCaretElectricityForecaster:
    def __init__(self):
        self.data = None
        self.ts_setup = None
        self.best_models = []
        self.model_results = {}
        self.tuned_models = {}

    def load_and_prepare_data(self, file_path=None, sample_data=True):
        """
        Load and prepare electricity consumption data
        """
        if sample_data or file_path is None:
            print("Creating realistic electricity consumption sample data...")

            # Create sample data with realistic patterns
            np.random.seed(42)

            # Date range: 2 years of hourly data
            start_date = '2022-01-01'
            end_date = '2023-12-31'
            dates = pd.date_range(start=start_date, end=end_date, freq='H')

            # Base consumption pattern
            base_consumption = 2.5

            # Daily pattern (peak during evening, low at night)
            hours = np.array([d.hour for d in dates])
            daily_pattern = (
                0.3 * np.sin(2 * np.pi * (hours - 6) / 24) +  # Main daily cycle
                0.2 * np.sin(2 * np.pi * (hours - 18) / 24) +  # Evening peak
                0.1 * np.cos(2 * np.pi * hours / 24)  # Additional variation
            )

            # Weekly pattern (higher on weekdays, lower on weekends)
            day_of_week = np.array([d.dayofweek for d in dates])
            weekly_pattern = 0.3 * (1 - 0.4 * (day_of_week >= 5))  # Lower on weekends

            # Seasonal pattern (higher in summer/winter, lower in spring/fall)
            day_of_year = np.array([d.dayofyear for d in dates])
            seasonal_pattern = (
                0.4 * np.sin(2 * np.pi * (day_of_year - 80) / 365) +  # Summer peak
                0.2 * np.cos(2 * np.pi * day_of_year / 365)  # Winter heating
            )

            # Random noise and occasional spikes
            noise = np.random.normal(0, 0.15, len(dates))
            spikes = np.random.exponential(0.1, len(dates)) * (np.random.random(len(dates)) < 0.02)

            # Combine all patterns
            consumption = (base_consumption + daily_pattern + weekly_pattern +
                         seasonal_pattern + noise + spikes)

            # Ensure positive values
            consumption = np.maximum(consumption, 0.1)

            # Add some additional realistic features
            temperature = 20 + 15 * np.sin(2 * np.pi * day_of_year / 365) + np.random.normal(0, 3, len(dates))
            humidity = 60 + 20 * np.sin(2 * np.pi * (day_of_year + 100) / 365) + np.random.normal(0, 5, len(dates))

            self.data = pd.DataFrame({
                'datetime': dates,
                'Global_active_power': consumption,
                'temperature': temperature,
                'humidity': humidity
            })

        else:
            # Load actual dataset
            print(f"Loading data from {file_path}...")
            self.data = pd.read_csv(file_path, sep=';', low_memory=False)

            # Clean and prepare actual dataset
            self.data['datetime'] = pd.to_datetime(self.data['Date'] + ' ' + self.data['Time'])
            self.data['Global_active_power'] = pd.to_numeric(self.data['Global_active_power'], errors='coerce')

            # Select relevant columns
            columns_to_keep = ['datetime', 'Global_active_power']
            if 'Global_reactive_power' in self.data.columns:
                self.data['Global_reactive_power'] = pd.to_numeric(self.data['Global_reactive_power'], errors='coerce')
                columns_to_keep.append('Global_reactive_power')
            if 'Voltage' in self.data.columns:
                self.data['Voltage'] = pd.to_numeric(self.data['Voltage'], errors='coerce')
                columns_to_keep.append('Voltage')

            self.data = self.data[columns_to_keep]

        # Clean data
        self.data = self.data.dropna()
        self.data = self.data[self.data['Global_active_power'] > 0]

        # Set datetime as index
        self.data.set_index('datetime', inplace=True)

        # Resample to reduce computational load (optional)
        if len(self.data) > 20000:
            print("Resampling to 2-hourly data for faster processing...")
            self.data = self.data.resample('2H').mean()

        print(f"Dataset shape: {self.data.shape}")
        print(f"Date range: {self.data.index.min()} to {self.data.index.max()}")
        print(f"Target variable statistics:")
        print(self.data['Global_active_power'].describe())

        return self.data

    def setup_pycaret_environment(self, forecast_horizon=168, trainSize=0.8):
        """
        Setup PyCaret time series environment
        """
        if not PYCARET_AVAILABLE:
            print("PyCaret is not available. Please install it first.")
            return None

        print("Setting up PyCaret Time Series environment...")

        # Prepare data for PyCaret (needs target column and datetime index)
        ts_data = self.data[['Global_active_power']].copy()

        # Setup PyCaret time series
        self.ts_setup = setup(
            data=ts_data,
            target='Global_active_power',
            fh=forecast_horizon,  # Forecast horizon (1 week = 168 hours for hourly data)
            #train_size=trainSize,
            seasonal_period=[24, 168],  # Daily and weekly seasonality
            session_id=123,
            verbose=True
        )

        print("PyCaret setup completed!")
        return self.ts_setup

    def compare_models_comprehensive(self, include_models=None, sort_metric='RMSE'):
        """
        Compare multiple time series models using PyCaret
        """
        if not PYCARET_AVAILABLE or self.ts_setup is None:
            print("PyCaret environment not properly set up.")
            return None

        print("Comparing time series models...")

        # Available models in PyCaret for time series
        if include_models is None:
            # Let PyCaret compare all available models
            print("include models is None!")
            include_models = [
                'naive', 'snaive', 'polytrend',
                'arima', 'auto_arima', 'exp_smooth', 'croston',
                'ets', 'theta', 'tbats', 'prophet'
            ]

        try:
            # Compare models
            self.comparison_results = compare_models(
                include=include_models,
                sort=sort_metric,
                verbose=True
            )

            print("\nModel comparison completed!")
            return self.comparison_results

        except Exception as e:
            print(f"Error in model comparison: {e}")
            # Fallback to basic models if advanced ones fail
            basic_models = ['naive', 'snaive', 'exp_smooth', 'arima', 'prophet']
            print(f"Trying with basic models: {basic_models}")

            self.comparison_results = compare_models(
                include=basic_models,
                sort=sort_metric,
                verbose=True
            )

            return self.comparison_results

    def select_and_tune_top_models(self, n_models=5):
        """
        Select top N models and tune their hyperparameters
        """
        if not hasattr(self, 'comparison_results'):
            print("No comparison results available. Run compare_models_comprehensive first.")
            return None

        print(f"\nSelecting and tuning top {n_models} models...")

        # Get model names from comparison results
        if hasattr(self.comparison_results, 'index'):
            model_names = self.comparison_results.index[:n_models].tolist()
        else:
            # If comparison_results is a list or different format
            model_names = [f"top_{i+1}" for i in range(min(n_models, len(self.comparison_results)))]

        self.best_models = []
        self.tuned_models = {}

        for i in range(min(n_models, len(model_names))):
            try:
                print(f"\nTuning model {i+1}...")

                # Create model
                if hasattr(self.comparison_results, 'iloc'):
                    model = create_model(self.comparison_results.index[i])
                else:
                    # Fallback: create models by name
                    basic_models = ['naive', 'snaive', 'exp_smooth', 'arima', 'prophet']
                    if i < len(basic_models):
                        model = create_model(basic_models[i])
                    else:
                        continue

                # Tune hyperparameters
                tuned_model = tune_model(model)

                self.best_models.append(model)
                self.tuned_models[f"Model_{i+1}"] = tuned_model

                print(f"Model {i+1} tuned successfully!")

            except Exception as e:
                print(f"Error tuning model {i+1}: {e}")
                continue

        print(f"\nSuccessfully tuned {len(self.tuned_models)} models!")
        return self.tuned_models

    def evaluate_models(self):
        """
        Evaluate all tuned models
        """
        if not self.tuned_models:
            print("No tuned models available.")
            return None

        print("\nEvaluating tuned models...")

        self.model_results = {}

        for model_name, model in self.tuned_models.items():
            try:
                print(f"\nEvaluating {model_name}...")

                # Get predictions
                predictions = predict_model(model)

                # Store results
                self.model_results[model_name] = {
                    'model': model,
                    'predictions': predictions
                }

                print(f"{model_name} evaluated successfully!")

            except Exception as e:
                print(f"Error evaluating {model_name}: {e}")
                continue

        return self.model_results

    def visualize_results(self):
        """
        Create comprehensive visualizations of results
        """
        if not self.model_results:
            print("No model results available for visualization.")
            return

        print("Creating visualizations...")

        # 1. Model comparison from PyCaret
        if hasattr(self, 'comparison_results'):
            try:
                fig, ax = plt.subplots(1, 1, figsize=(12, 6))

                # Plot comparison results
                metrics = ['RMSE', 'MAE', 'MAPE'] if 'RMSE' in self.comparison_results.columns else self.comparison_results.columns[:3]

                comparison_plot = self.comparison_results[metrics].head(10)
                comparison_plot.plot(kind='bar', ax=ax)
                ax.set_title('Model Performance Comparison')
                ax.set_xlabel('Models')
                ax.set_ylabel('Error Metrics')
                ax.legend()
                plt.xticks(rotation=45)
                plt.tight_layout()
                plt.show()

            except Exception as e:
                print(f"Error creating comparison plot: {e}")

        # 2. Individual model predictions
        fig, axes = plt.subplots(len(self.model_results), 1, figsize=(15, 4*len(self.model_results)))
        if len(self.model_results) == 1:
            axes = [axes]

        for i, (model_name, results) in enumerate(self.model_results.items()):
            try:
                # Plot predictions using PyCaret's built-in plotting
                plot_model(results['model'], plot='forecast', display_format='streamlit')

            except Exception as e:
                print(f"Error plotting {model_name}: {e}")

        plt.tight_layout()
        plt.show()

    def get_best_model_summary(self):
        """
        Get summary of the best performing model
        """
        if hasattr(self, 'comparison_results') and not self.comparison_results.empty:
            print("\n" + "="*60)
            print("TOP 5 MODELS PERFORMANCE SUMMARY")
            print("="*60)

            # Display top 5 models
            top_5 = self.comparison_results.head(5)
            print(top_5)

            # Best model details
            best_model_name = self.comparison_results.index[0]
            print(f"\nBest Model: {best_model_name}")
            print(f"Performance Metrics:")

            for metric in self.comparison_results.columns:
                value = self.comparison_results.iloc[0][metric]
                print(f"  {metric}: {value:.4f}")

        return self.comparison_results.head(5) if hasattr(self, 'comparison_results') else None

    def run_complete_analysis(self, file_path=None, forecast_horizon=168):
        """
        Run the complete forecasting analysis pipeline
        """
        print("Starting Complete Electricity Forecasting Analysis with PyCaret")
        print("="*65)

        # Step 1: Load and prepare data
        self.load_and_prepare_data(file_path)
        print("load and prepare data done!")

        # Step 2: Setup PyCaret environment
        self.setup_pycaret_environment(forecast_horizon=forecast_horizon)
        print("setup pycaret env done!")
        include_models = compare_models()
        # Step 3: Compare models
        self.compare_models_comprehensive(include_models)
        print("compare models done!")

        # Step 4: Select and tune top models
        self.select_and_tune_top_models(n_models=5)
        print("select and tune top models done!")

        # Step 5: Evaluate models
        self.evaluate_models()
        print("evaluate models done!")

        # Step 6: Visualize results
        self.visualize_results()

        # Step 7: Summary
        summary = self.get_best_model_summary()

        print("\n" + "="*65)
        print("ANALYSIS COMPLETE!")
        print("="*65)

        return summary

#!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00235/household_power_consumption.zip
#!unzip household_power_consumption.zip

# Example usage and main execution
if __name__ == "__main__":

    if not PYCARET_AVAILABLE:
        print("Please install PyCaret first:")
        print("pip install pycaret")
        print("\nAlternatively, install the full suite:")
        print("pip install pycaret[full]")
        exit()

    # Initialize the forecaster
    forecaster = PyCaretElectricityForecaster()

    # Run complete analysis
    print("Welcome to PyCaret Electricity Consumption Forecasting!")
    print("This will automatically compare and tune the top 5 time series models.")
    print("\nStarting analysis...")

    try:
        # Run with sample data (set file_path to your actual data file)
        results = forecaster.run_complete_analysis(
            file_path='household_power_consumption.txt',  # Replace with "path/to/household_power_consumption.txt"
            forecast_horizon=168  # 1 week forecast (168 hours)
        )
        print("\nTo use with your actual dataset:")
        print("1. Download from: https://archive.ics.uci.edu/dataset/235/individual+household+electric+power+consumption")
        print("2. Replace file_path=None with file_path='your_data_path.txt'")
        print("3. Ensure PyCaret is installed: pip install pycaret")

    except Exception as e:
        print(f"Error in analysis: {e}")
        print("\nTrying with basic configuration...")

        # Fallback to basic setup
        try:
            forecaster.load_and_prepare_data()
            print("Sample data loaded successfully!")
            print("PyCaret setup completed with sample data.")

        except Exception as e2:
            print(f"Error with basic setup: {e2}")
            print("Please check PyCaret installation and try again.")

print("\n" + "="*65)
print("PYCARET ELECTRICITY FORECASTING SCRIPT")
print("="*65)
print("Features:")
print("• Automatic model comparison and selection")
print("• Hyperparameter tuning for top 5 models")
print("• Built-in time series validation")
print("• Professional visualizations")
print("• Seasonal pattern detection")
print("• One-click forecasting pipeline")
print("="*65)